{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Performance of the IR system is graded with different combinations of query matching models and IR models.\n",
    "\n",
    "Different preprocessing techniques are investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"index\" directory will contain different versions of the index as subdirectories.\n",
    "# Make the directory if not created already.\n",
    "\n",
    "import os\n",
    "os.mkdir(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from placerank.dataset import populate_index\n",
    "from placerank.preprocessing import ANALYZER_NAIVE, ANALYZER_STEMMER, ANALYZER_LEMMATIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index using the naive analyzer.\n",
    "\n",
    "Text in the naive analyzer is processed through this pipeline:\n",
    "\n",
    "- tokenization\n",
    "\n",
    "- conversion to lowercase\n",
    "\n",
    "- stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_index(\"index/naive\", ANALYZER_NAIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemmer analyzer\n",
    "\n",
    "This preprocessing adds a stage to the previous pipeline. Words are stemmed.\n",
    "\n",
    "Whoosh StemFilter uses Porter's Stemmer algorithm and extracts root from words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_index(\"index/stem\", ANALYZER_STEMMER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizer Analyzer\n",
    "\n",
    "This preprocessing adds a lemmatization step to the first pipeline, but stop words removal is performed after the lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_index(\"index/lemma\", ANALYZER_LEMMATIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crisp sets\n",
    "\n",
    "The crisp set model is a set theoretical model based on the classic set operations.\n",
    "The theoretical framework provides a membership function that tells if each document is relevant to the query or not.\n",
    "\n",
    "A document is relevant if and only if it matches completely the query (i.e. contains every term for simple \"AND\" queries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the inverted index processed using the naive pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import open_dir\n",
    "\n",
    "naive_ix = open_dir(\"index/naive\")\n",
    "stem_ix = open_dir(\"index/stem\")\n",
    "lemma_ix = open_dir(\"index/lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from placerank.search import boolean_search\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a93a86301a46018294797512b8f81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='flat in manhattan', description='Query:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queryField = widgets.Text(\n",
    "    value=\"flat in manhattan\",\n",
    "    description=\"Query:\"\n",
    ")\n",
    "display(queryField)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14528\n",
      "30049\n",
      "15843\n",
      "15974\n",
      "6727\n",
      "10248\n",
      "14665\n",
      "8266\n",
      "843\n",
      "19560\n",
      "28556\n",
      "7410\n",
      "12787\n",
      "16151\n"
     ]
    }
   ],
   "source": [
    "res = boolean_search(naive_ix, queryField.value)\n",
    "print(*[r for r in res], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the effect of stemming on the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14528\n",
      "30049\n",
      "15843\n",
      "15974\n",
      "6727\n",
      "10248\n",
      "14665\n",
      "8266\n",
      "843\n",
      "19560\n",
      "28556\n",
      "7410\n",
      "12787\n",
      "16151\n"
     ]
    }
   ],
   "source": [
    "res = boolean_search(stem_ix, queryField.value)\n",
    "print(*[r for r in res], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what's different using lemmatization instead of stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14528\n",
      "30049\n",
      "15843\n",
      "15974\n",
      "6727\n",
      "10248\n",
      "14665\n",
      "8266\n",
      "843\n",
      "19560\n",
      "28556\n",
      "7410\n",
      "12787\n",
      "16151\n"
     ]
    }
   ],
   "source": [
    "res = boolean_search(lemma_ix, queryField.value)\n",
    "print(*[r for r in res], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector-space model\n",
    "\n",
    "Comparison of different retrieval techniques for the default index, which has been processed with the default analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from placerank.search import vector_boolean_search, vector_tfidf_search, vector_bm25_search\n",
    "from whoosh.index import open_dir\n",
    "import ipywidgets as widgets\n",
    "\n",
    "ix = open_dir(\"index/lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8fd0053a734c1e9519c10c4f17206a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='flat in manhattan', description='Query:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queryField = widgets.Text(\n",
    "    value=\"flat in manhattan\",\n",
    "    description=\"Query:\"\n",
    ")\n",
    "display(queryField)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(*vector_boolean_search(ix, queryField.value))\n",
    "print(*vector_tfidf_search(ix, queryField.value))\n",
    "print(*vector_bm25_search(ix, queryField.value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
