{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Performance of the IR system is graded with different combinations of query matching models and IR models.\n",
    "\n",
    "Different preprocessing techniques are investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"index\" directory will contain different versions of the index as subdirectories.\n",
    "# Make the directory if not created already.\n",
    "\n",
    "import os\n",
    "os.mkdir(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from placerank.dataset import populate_index\n",
    "from placerank.preprocessing import ANALYZER_NAIVE, ANALYZER_STEMMER, ANALYZER_LEMMATIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index using the naive analyzer.\n",
    "\n",
    "Text in the naive analyzer is processed through this pipeline:\n",
    "\n",
    "- tokenization\n",
    "\n",
    "- conversion to lowercase\n",
    "\n",
    "- stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_index(\"index/naive\", ANALYZER_NAIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemmer analyzer\n",
    "\n",
    "This preprocessing adds a stage to the previous pipeline. Words are stemmed.\n",
    "\n",
    "Whoosh StemFilter uses Porter's Stemmer algorithm and extracts root from words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_index(\"index/stem\", ANALYZER_STEMMER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizer Analyzer\n",
    "\n",
    "This preprocessing adds a lemmatization step to the first pipeline, but stop words removal is performed after the lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_index(\"index/lemma\", ANALYZER_LEMMATIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crisp sets\n",
    "\n",
    "The crisp set model is a set theoretical model based on the classic set operations.\n",
    "The theoretical framework provides a membership function that tells if each document is relevant to the query or not.\n",
    "\n",
    "A document is relevant if and only if it matches completely the query (i.e. contains every term for simple \"AND\" queries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector-space model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Indipendence Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
